好的，这是一份关于 **EM算法** 的详细学习笔记。它将从解决什么问题出发，逐步深入到算法的核心思想、数学推导以及其与K-Means的联系。

---

## **EM算法学习笔记**

### **1. 核心思想与解决的问题**

**EM算法** 是一种用于**含有隐变量** 的概率模型参数的**迭代优化算法**。

*   **问题场景**：我们想估计一个概率模型的参数，但模型中存在我们无法直接观测到的**隐变量**。
*   **核心直觉**：既然有些变量我们观测不到，导致无法直接进行最大似然估计，那我们就先“猜”一下这些隐变量的分布（**E步**），然后基于这个猜测去优化参数（**M步**）。不断重复这个过程，直到参数收敛。

**一个经典比喻：分蛋糕**
> 有两个厨师A和B分一个蛋糕，但不知道谁做的蛋糕更好吃。怎么办呢？
> 1.  **E步（期望步）**：先随机给A和B一个“水平评分”。根据这个评分，将蛋糕的每一部分按“属于A做的可能性”和“属于B做的可能性”分成两份软分配。
> 2.  **M步（最大化步）**：现在，A得到了所有“可能属于他做的”蛋糕部分（有的大，有的小），他根据自己得到的这部分蛋糕重新评估自己的水平（更新参数）。B也同样操作。
> 3.  **迭代**：用新的水平评分，回到E步重新分蛋糕... 如此循环，直到两个人的水平评分稳定下来。这时，我们就不仅知道了蛋糕各部分最可能出自谁手，也知道了两位厨师的水平。

---

### **2. 算法流程**

给定观测数据 \( X \)，隐变量 \( Z \)，模型参数 \( \theta \)。
我们的目标是找到参数 \( \theta \) 使得观测数据的似然函数 \( P(X|\theta) \) 最大。
但由于 \( Z \) 未知，直接优化 \( P(X|\theta) \) 很困难。

EM算法通过迭代以下两步来求解：

#### **第一步：期望步**

**目标**：在固定参数 \( \theta^{(t)} \) 的情况下，计算**完全数据** \( (X, Z) \) 的似然函数关于隐变量 \( Z \) 的期望。
构建一个函数 \( Q(\theta, \theta^{(t)}) \)，这个函数是**在当前参数 \( \theta^{(t)} \) 和观测数据 \( X \) 下，完整数据似然的对数的期望**。

\[
Q(\theta, \theta^{(t)}) = E_{Z|X, \theta^{(t)}}[\log P(X, Z | \theta)]
\]

更具体地：
\[
Q(\theta, \theta^{(t)}) = \sum_{Z} P(Z|X, \theta^{(t)}) \log P(X, Z | \theta)
\]

*   **\( P(Z|X, \theta^{(t)}) \)**：这是在当前参数下，隐变量的**后验分布**。E步的核心就是计算这个后验分布。
*   **物理意义**：我们基于当前最好的模型 \( \theta^{(t)} \)，为每一个可能的隐变量分配一个“责任”（Responsibility），即它出现的概率。这就像是**给未知的隐变量做了一个“软填充”**。

#### **第二步：最大化步**

**目标**：找到一个新参数 \( \theta^{(t+1)} \)，使得上述期望 \( Q \) 函数最大化。

\[
\theta^{(t+1)} = \arg\max_{\theta} Q(\theta, \theta^{(t)})
\]

*   **物理意义**：现在我们有了一个关于隐变量的“软分配”（来自E步），就可以像没有隐变量一样，通过最大化这个加权的完整数据似然来更新模型参数。这通常比直接最大化 \( P(X|\theta) \) 要简单。

#### **迭代**
重复执行E步和M步，直到参数 \( \theta \) 的变化小于某个阈值，或似然函数不再显著增加。

---

### **3. 与K-Means和软K-Means的联系**

理解这个联系是掌握EM思想的关键。

| 算法 | **隐变量 (Z)** | **E步 (计算期望)** | **M步 (最大化期望)** |
| :--- | :--- | :--- | :--- |
| **K-Means** | 每个数据点的**簇标签** \( r_{ik} \in \{0, 1\} \) | **硬分配**：<br> \( r_{ik} = \begin{cases} 1 & \text{if } k = \arg\min_j ||x_i - \mu_j||^2 \\ 0 & \text{otherwise} \end{cases} \) | **更新质心**：<br> \( \mu_k = \frac{\sum_i r_{ik} x_i}{\sum_i r_{ik}} \) |
| **软K-Means** | 每个数据点的**归属度** \( r_{ik} \in [0, 1] \) | **软分配**：<br> \( r_{ik} = \frac{\exp(-\beta ||x_i - \mu_k||^2)}{\sum_j \exp(-\beta ||x_i - \mu_j||^2)} \) | **加权更新质心**：<br> \( \mu_k = \frac{\sum_i r_{ik} x_i}{\sum_i r_{ik}} \) |
| **EM算法 (用于GMM)** | 每个数据点的**簇责任** \( \gamma(z_{ik}) \)，等同于 \( r_{ik} \) | **计算责任**：<br> \( \gamma(z_{ik}) = \frac{\pi_k \mathcal{N}(x_i|\mu_k, \Sigma_k)}{\sum_j \pi_j \mathcal{N}(x_i|\mu_j, \Sigma_j)} \) | **加权更新所有参数**：<br> \( \mu_k = \frac{\sum_i \gamma(z_{ik}) x_i}{\sum_i \gamma(z_{ik})} \) <br> \( \Sigma_k = \frac{\sum_i \gamma(z_{ik}) (x_i - \mu_k)(x_i - \mu_k)^T}{\sum_i \gamma(z_{ik})} \) <br> \( \pi_k = \frac{\sum_i \gamma(z_{ik})}{N} \) |

**结论**：
*   **K-Means** 是EM思想的一种**硬分配**的特例。
*   **软K-Means** 是EM算法应用于**各向同性高斯分布混合模型**的一个特例（协方差矩阵 \( \Sigma_k = \sigma^2 I \)）。
*   **完整的EM算法**（用于高斯混合模型）是软K-Means的**泛化**，它还能学习每个簇的**协方差矩阵（形状）** 和**先验权重（大小）**。

---

### **4. 一个简单的例子：抛硬币问题**

这是理解EM最经典的例子。

**问题**：有两枚不公平的硬币A和B，我们想估计它们正面朝上的概率 \( \theta_A \) 和 \( \theta_B \)。
**实验**：随机选一枚硬币，连续抛5次，重复做5轮实验。
**观测数据（X）**：我们只能看到每轮的抛掷结果，例如 `[HTTHT]`, `[HHHTH]`, ...，但**不知道每轮用的是哪枚硬币（Z）**。

*   **E步**：
    *   基于当前对 \( \theta_A, \theta_B \) 的猜测，计算每一轮实验来自硬币A的**概率（责任）**。
    *   例如，如果一轮结果是3正2反，而当前 \( \theta_A \) 较高，那么这轮数据“属于”硬币A的责任就更大。
    *   计算：\( P(Z=A|X, \theta) \propto P(X|Z=A, \theta) P(Z=A) \)。（通常假设选择硬币的先验概率是0.5）

*   **M步**：
    *   现在，我们不是简单地把一轮实验归给A或B，而是用E步计算出的“责任”作为权重。
    *   更新 \( \theta_A \)：将**所有轮次中正面的次数**，按“属于A的责任”进行加权求和，然后除以**所有轮次的总抛掷次数**（也按责任加权）。这给出了一个新的、更好的 \( \theta_A \) 估计。
    *   同理更新 \( \theta_B \)。

通过迭代，EM算法可以成功地从不完整的数据中估计出两枚硬币各自的正面概率。

---

### **5. 为什么EM算法有效？**

EM算法能够保证**观测数据的似然函数 \( P(X|\theta) \) 在每次迭代后都不会减少**，即 \( \log P(X|\theta^{(t+1)}) \ge \log P(X|\theta^{(t)}) \)。

其背后是**Jensen不等式**的应用。通过E步和M步的构造，我们实际上是在优化似然函数 \( \log P(X|\theta) \) 的一个**下界**（即ELBO, Evidence Lower BOund）。在E步，我们让这个下界紧贴当前的似然值；在M步，我们通过优化参数来提升这个下界，从而也提升了似然函数本身。

---

### **6. 优缺点总结**

#### **优点**
*   **概念直观**：为含有隐变量的模型提供了一个强大的估计框架。
*   **保证收敛**：总能收敛到一个局部最优解（但未必是全局最优）。
*   **M步通常有解析解**：对于许多指数族分布，M步的优化非常简单。

#### **缺点**
*   **对初始值敏感**：容易陷入局部最大值。通常需要多次随机初始化。
*   **收敛速度可能慢**：尤其是在接近最优解时。
*   **只能找到局部最优解**。
*   **需要指定隐变量结构**：比如混合模型中的簇数K。

p.s. EM算法相比Newton迭代法而言更容易收敛到全局极值点而非局部极值点