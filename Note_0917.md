Chapter 1 : 概率
=========
### 概率论基础
**概率密度函数(probability density function, pdf)**:
**概率分布函数(probability mass function, pmf)**:
**联合概率(joint probability)**:
**边际分布(marginal density)**:
**条件概率(conditional probability)**

### 随机变量的变换
For $Y = g(X)$ with inverse $X = h(Y)$,$$f_Y(y) = f_X(h(y))\cdot \left| \frac{dh}{dy} \right|$$

### 概率的特征
**平均值Mean**
**方差Variance**
**协方差Covariance**:$Cov (X,Y) = \mathbb{E}[(X-\mu_X)(Y-\mu_Y)] = E(XY)-E(X)E(Y)$
- positive covariance:
- negative covariance:
- zero covariance:No linear relationship,but may have nonlinear dependence
  即:独立一定不相关,不相关不一定独立

### 熵(Entropy):衡量不确定性与随机性
Entropy measures the uncertainty or randomness of a random variable 
**For discrete random variables**:$$H(X)=-\sum_{x\in \mathcal{X}}P(x)\log_2 P(x)$$以比特为单位（当使用以 2 为底的对数时）
熵越高,不确定性越强.熵越低,可预测性越强.


===== Page 2 =====

概率论基础 I
关键概念与定义

概率密度函数（PDF）
连续随机变量 \( X \) 的概率分布由一个满足以下条件的函数 \( p(x) \) 描述：

\[p(x) \geq 0 \quad (\text{非负性})\]
\[\int p(x) dx = 1 \quad (\text{归一化})\]

多元分布的关键密度函数

===== Page 3 =====

概率论基础 II
关键概念与定义

对于两个随机变量 \( X \) 和 \( Y \)，我们定义：

- **联合密度：** \( p(x, y) \)
- **边缘密度：** \( p(x) = \int p(x, y)dy \) （"求和掉"另一个变量）
- **条件密度：** \( p(x|y) \) 和 \( p(y|x) \)

基本乘积规则
这些密度之间的关系由下式给出：

\[p(x, y) = p(x|y)p(y) = p(y|x)p(x)\]

该规则是 **贝叶斯定理** 的基础：

\[p(y|x) = \frac{p(x|y)p(y)}{p(x)}.\]

分布的重要特征

===== Page 4 =====

概率论基础 III
关键概念与定义

- **均值 (\(\mu\))：** 期望值，衡量集中趋势。
  \[  \mathbb{E}[X] = \mu = \int xp(x)dx\]

- **方差 (\(\sigma^2\))：** 衡量围绕均值的散布或离散程度。
  \[  \text{Var}(X) = \sigma^2 = \int (x - \mu)^2 p(x)dx\]

- **熵 (\(H\))：** 衡量平均不确定性或信息内容。
  \[  H(X) = -\sum p(x)\log_2 p(x) \quad (\text{对于离散变量})\]
  我们有联合熵 \(H(X,Y)\)，条件熵 \(H(X|Y), H(Y|X)\) 和互信息 \(I(X;Y)\)。相对熵
  \[  D(P||Q) = \int p(x)\log\frac{p(x)}{q(x)}dx \quad \text{起着关键作用}\]

===== Page 5 =====

# 熵的用途

**定理（最大熵分布）**
在所有具有固定均值 \(\mu\) 和方差 \(\sigma^2\) 的连续概率分布 \( p(x) \) 中，高斯分布

\[q(x) = \mathcal{N}(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)\]

达到 **最大微分熵**：

\[h(p) = -\int p(x) \log p(x) dx \leq \frac{1}{2} \log(2\pi e\sigma^2) = h(q)\]

当且仅当 \( p(x) = q(x) \) 时取等号。
\(\Rightarrow\) 对于给定的均值和方差，高斯分布是 **信息量最少** 的分布。

===== Page 6 =====

# 证明设置：KL 散度

该证明利用了 **Kullback-Leibler (KL) 散度** 的非负性。

## KL 散度
从 \( q \) 到 \( p \) 的 KL 散度衡量了分布之间的"距离"：

\[D_{KL}(p \parallel q) = \int p(x) \log \frac{p(x)}{q(x)} dx\]

其关键性质是：

\[D_{KL}(p \parallel q) \geq 0\]

当且仅当 \( p(x) = q(x) \) 几乎处处成立时取等号。

===== Page 7 =====

步骤 1：展开 KL 散度

让我们展开目标高斯分布 \( q \) 的 \( D_{KL}(p \parallel q) \)：

\[D_{KL}(p \parallel q) = \int p(x) \log \frac{p(x)}{q(x)} dx\]

\[= \int p(x) \log p(x) dx - \int p(x) \log q(x) dx\]

\[= -h(p) - \int p(x) \log q(x) dx\]

由于 \( D_{KL}(p \parallel q) \geq 0 \)，我们有：

\[-h(p) - \int p(x) \log q(x) dx \geq 0 \quad \Rightarrow \quad h(p) \leq - \int p(x) \log q(x) dx\]

\[\Rightarrow \quad \text{我们现在得到了 } h(p) \text{ 的一个上界}\]

===== Page 8 =====

步骤 2：计算上界

我们需要计算 \(-\int p(x)\log q(x)dx\)。首先，写出高斯分布 \(q(x)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)\) 的 \(\log q(x)\)：

\[\log q(x) = \log\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right) - \frac{(x-\mu)^2}{2\sigma^2} = -\frac{1}{2}\log(2\pi\sigma^2) - \frac{(x-\mu)^2}{2\sigma^2}\]

现在将其代入积分：

\[-\int p(x)\log q(x)dx = -\int p(x)\left(-\frac{1}{2}\log(2\pi\sigma^2) - \frac{(x-\mu)^2}{2\sigma^2}\right)dx\]

\[= \int p(x)\left(\frac{1}{2}\log(2\pi\sigma^2) + \frac{(x-\mu)^2}{2\sigma^2}\right)dx\]

===== Page 9 =====

步骤 3：使用约束条件

分配积分并利用 \( p(x) \) 的约束条件：

\[- \int p(x) \log q(x) dx = \frac{1}{2} \log (2\pi\sigma^2) \int p(x) dx + \frac{1}{2\sigma^2} \int p(x)(x - \mu)^2 dx\]

根据定义，我们的分布 \( p(x) \) 满足：

- \[ \int p(x) dx = 1 \] （归一化）
- \[ \int p(x)(x - \mu)^2 dx = \sigma^2 \] （方差的定义）

代入这些条件：

\[- \int p(x) \log q(x) dx = \frac{1}{2} \log (2\pi\sigma^2) \cdot 1 + \frac{1}{2\sigma^2} \cdot \sigma^2\]

\[= \frac{1}{2} \log (2\pi\sigma^2) + \frac{1}{2}\]

===== Page 10 =====

步骤 4：最终推导与结果

简化表达式：

\[\frac{1}{2} \log(2\pi\sigma^2) + \frac{1}{2} = \frac{1}{2} \left( \log(2\pi\sigma^2) + 1 \right)\]

\[= \frac{1}{2} \left( \log(2\pi\sigma^2) + \log(e) \right) \quad (\text{因为 } 1 = \log e)\]

\[= \frac{1}{2} \log(2\pi e\sigma^2)\]

但这正是高斯分布 \( q(x) \) 的微分熵：

\[h(q) = \frac{1}{2} \log(2\pi e\sigma^2)\]

===== Page 11 =====

步骤 5：结论

回顾我们从步骤 1 得到的不等式：

\[h(p) \leq -\int p(x) \log q(x) dx\]

我们刚刚证明了：

\[-\int p(x) \log q(x) dx = \frac{1}{2} \log (2\pi e\sigma^2) = h(q)\]

因此，我们得出结论：

\[h(p) \leq h(q)\]

等号成立条件
当且仅当 \( D_{KL}(p \parallel q) = 0 \) 时等号成立，这当且仅当 \( p(x) = q(x) \) 几乎处处成立。

===== Page 12 =====

# 重要的概率分布

## 1. 高斯（正态）分布：

\[p(x|\mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)\]

均值 \(\mu\)，方差 \(\sigma^2\)，这些是参数。

## 2. 伯努利分布（离散）：

\[\text{Ber}(x|\mu) = \mu^x(1 - \mu)^{1-x}\]

- \(P(x = 0) = 1 - \mu\), \(P(x = 1) = \mu\)
- 均值 \(\mu\)，方差 \(\mu(1 - \mu)\)

===== Page 13 =====

多元分布
多元（n 维）高斯分布

\[P(\mathbf{x}|\mu, \Sigma) = \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x} - \mu)^T\Sigma^{-1}(\mathbf{x} - \mu)\right)\]

均值向量 \(\mu\)（n 维向量），协方差矩阵 \(\Sigma\)（\(n \times n\) 矩阵）。
分类分布
对于 \(K\) 个类别：

\[P(t = i) = p_i \quad (i = 1, \ldots, K), \quad \sum_{i=1}^{K} p_i = 1\]

紧凑表示：

\[P(t) = \prod_{i=1}^{K} p_i^{t_i}\]

===== Page 14 =====

独热编码表示

► t 是一个独热编码的 \( n \) 维向量
► \( t_i \) 表示 t 的第 \( i \) 个分量

例子：
- 类别 1: \( t = [1,0,0,\ldots,0] \)
- 类别 2: \( t = [0,1,0,\ldots,0] \)
- 类别 \( K \): \( t = [0,0,\ldots,1] \)

恰好有一个分量为 1，所有其他分量为 0

===== Page 15 =====

正态分布
连续多元概率的基石

一个随机向量 \( \mathbf{X} = [X_1, X_2, ..., X_D]^T \) 服从多元高斯分布，如果其概率密度函数（PDF）为：

概率密度函数（PDF）

\[p(\mathbf{x}|\mu, \Sigma) = \frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x} - \mu)^T \Sigma^{-1}(\mathbf{x} - \mu)\right)\]

- \(\mu \in \mathbb{R}^D\): 均值向量（分布的中心）
- \(\Sigma \in \mathbb{R}^{D \times D}\): 协方差矩阵（对称，正定）
- 对角线元素 \(\Sigma_{ii}\): 每个变量 \(X_i\) 的方差
- 非对角线元素 \(\Sigma_{ij}\): 变量 \(X_i\) 和 \(X_j\) 之间的协方差

记号

\[\mathbf{X} \sim \mathcal{N}(\mu, \Sigma)\]

===== Page 16 =====

关键性质与向量划分
该分布完全由其均值和协方差定义：

\[\mathbb{E}[X] = \mu\]
\[\text{Cov}[X] = \Sigma\]

向量与矩阵的划分
为了分析边缘分布和条件分布，我们对向量及其参数进行划分：

\[X =
\begin{bmatrix}
X_a \\
X_b
\end{bmatrix}, \quad \mu =
\begin{bmatrix}
\mu_a \\
\mu_b
\end{bmatrix}, \quad \Sigma =
\begin{bmatrix}
\Sigma_{aa} & \Sigma_{ab} \\
\Sigma_{ba} & \Sigma_{bb}
\end{bmatrix}\]

- \( X_a \) 是 \( p \times 1 \)，\( X_b \) 是 \( q \times 1 \) (\( p + q = D \))。
- \( \Sigma_{aa} \): \( X_a \) 的协方差。
- \( \Sigma_{bb} \): \( X_b \) 的协方差。
- \( \Sigma_{ab} = \Sigma_{ba}^T \): \( X_a \) 和 \( X_b \) 之间的互协方差。

===== Page 17 =====

# 边缘分布

变量子集的分布

**定理（边缘分布是高斯分布）**
如果 \[ \begin{bmatrix} X_a \\ X_b \end{bmatrix} \sim N \left( \begin{bmatrix} \mu_a \\ \mu_b \end{bmatrix}, \begin{bmatrix} \Sigma_{aa} & \Sigma_{ab} \\ \Sigma_{ba} & \Sigma_{bb} \end{bmatrix} \right) \]，那么边缘分布也是高斯分布：

\[p(X_a) = N(X_a | \mu_a, \Sigma_{aa}) \]
\[p(X_b) = N(X_b | \mu_b, \Sigma_{bb})\]

---

## 解释

要得到任何变量子集的边缘分布：

1. 从均值 \( \mu \) 中提取对应的子向量。
2. 从协方差 \( \Sigma \) 中提取对应的子矩阵。

边缘分布 **忽略**（积分掉）其他变量，但通过其自身子矩阵中的协方差保留它们的影响。

===== Page 18 =====

# 条件分布

给定其他变量时，某个子集的分布
定理（条件分布是高斯分布）

条件分布 \( p(X_a|X_b) \) 也是高斯分布：

\[p(X_a|X_b) = \mathcal{N}(X_a|\mu_{a|b}, \Sigma_{a|b})\]

参数为：

\[\mu_{a|b} = \mu_a + \Sigma_{ab}\Sigma_{bb}^{-1}(X_b - \mu_b)\]
\[\Sigma_{a|b} = \Sigma_{aa} - \Sigma_{ab}\Sigma_{bb}^{-1}\Sigma_{ba}\]

---

## 解释

- **条件均值** \(\mu_{a|b}\) 是值 \(X_b\) 的线性函数。
- **条件协方差** \(\Sigma_{a|b}\) 是常数（它不依赖于 \(X_b\) 的值）。这是高斯分布的一个特殊性质。

===== Page 19 =====

# 总结：多元高斯分布

- **由以下定义：** 均值向量 \( \mu \) 和协方差矩阵 \( \Sigma \)。
- **线性变换：** 高斯向量的任何线性变换本身也是高斯分布。
  \[  Y = AX + b \implies Y \sim \mathcal{N}(A\mu + b, A\Sigma A^T)\]

- **边缘分布：** 是高斯分布。它们的参数通过选择 \( \mu \) 和 \( \Sigma \) 的相关子向量和子矩阵找到。

- **条件分布：** 是高斯分布。它们的参数通过对 \( \Sigma \) 的块进行矩阵求逆和乘法找到。

- **特殊情况：** 独立性：如果 \( \Sigma_{ab} = 0 \)（块之间独立），那么 \( p(\mathbf{X}_a|\mathbf{X}_b) = p(\mathbf{X}_a) \) 且 \( \mu_{a|b} = \mu_a \)，
  \[  \Sigma_{a|b} = \Sigma_{aa}\]

---

**高斯分布族在边缘化和条件化下是封闭的。**

===== Page 20 =====

表格：常见概率分布

| 分布       | 概率质量/密度函数 (PMF/PDF)                                  | 参数与支撑集                                       | 均值与方差       |
|------------|-------------------------------------------------------------|----------------------------------------------------|------------------|
| 离散分布   |                                                             |                                                    |                  |
| 伯努利     | \( P(X = x) \) \( p \) 若 \( x = 1 \) \( 1 - p \) 若 \( x = 0 \) | \( p \in [0, 1] \) (成功概率) \( x \in \{0, 1\} \) | \( \mu = p \) \( \sigma^2 = p(1 - p) \) |
| 二项       | \( P(X = k) = \binom{n}{k}p^k(1 - p)^{n-k} \)                 | \( n \in \mathbb{N} \) (试验次数) \( p \in [0, 1] \) (成功概率) \( k \in \{0, 1, ..., n\} \) | \( \mu = np \) \( \sigma^2 = np(1 - p) \) |
| 泊松       | \( P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!} \)            | \( \lambda > 0 \) (速率) \( k \in \mathbb{Z}_{\geq 0} \) | \( \mu = \lambda \) \( \sigma^2 = \lambda \) |
| 几何       | \( P(X = k) = (1 - p)^{k-1}p \)                              | \( p \in (0, 1] \) (成功概率) \( k \in \mathbb{Z}^+ \) (直到成功的试验次数) | \( \mu = \frac{1}{p} \) \( \sigma^2 = \frac{1-p}{p^2} \) |
| 负二项     | \( P(X = k) = \binom{k-1}{r-1}(1 - p)^{k-r}p^r \)             | \( r \in \mathbb{Z}^+ \) (成功次数) \( p \in (0, 1] \) (成功概率) \( k \in \{r, r + 1, ...\} \) | \( \mu = \frac{r}{p} \) \( \sigma^2 = \frac{r(1-p)}{p^2} \) |

===== Page 21 =====

| 分布       | 概率质量/密度函数 (PMF/PDF)                                  | 参数与支撑集                                       | 均值与方差       |
|------------|-------------------------------------------------------------|----------------------------------------------------|------------------|
| 连续分布   |                                                             |                                                    |                  |
| 均匀       | \( f(x) \) \(\begin{cases} \frac{1}{b-a} & \text{for } x \in [a, b] \\ 0 & \text{otherwise} \end{cases}\) | \( a, b \in \mathbb{R}, \, a < b \) \( x \in [a, b] \) | \(\mu = \frac{a+b}{2}\) \(\sigma^2 = \frac{(b-a)^2}{12}\) |
| 正态（高斯） | \( f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2} \) | \(\mu \in \mathbb{R} \, (\text{位置}) \) \(\sigma > 0 \, (\text{尺度}) \) \( x \in \mathbb{R} \) | \(\mu\) \(\sigma^2\) |
| 指数       | \( f(x) = \lambda e^{-\lambda x} \)                           | \(\lambda > 0 \, (\text{速率}) \) \( x \geq 0 \) | \(\mu = \frac{1}{\lambda}\) \(\sigma^2 = \frac{1}{\lambda^2}\) |
| 伽马       | \( f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x} \) | \(\alpha > 0 \, (\text{形状}), \, \beta > 0 \, (\text{速率}) \) \( x > 0 \) | \(\mu = \frac{\alpha}{\beta}\) \(\sigma^2 = \frac{\alpha}{\beta^2}\) |
| 贝塔       | \( f(x) = \frac{x^{\alpha-1}(1-x)^{\beta-1}}{B(\alpha,\beta)} \) | \(\alpha > 0, \, \beta > 0 \, (\text{形状}) \) \( x \in [0, 1] \) | \(\mu = \frac{\alpha}{\alpha+\beta}\) \(\sigma^2 = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\) |

===== Page 22 =====

# 高维分布建模

我们已经描述了一维分布的族。对于高维分布——除了多元高斯分布——我们将主要考虑以下模型：

1. **独立同分布 (i.i.d.)**
   随机变量相互独立，并且共享由 \( w \) 参数化的相同分布。

\[p(x_1, \ldots, x_n  |  w) = \prod_{i=1}^n p(x_i  |  w)\]

2. **马尔可夫链**

3. **图模型**（由图编码的概率模型）

我们将在后面讨论马尔可夫链和图模型。现在，我们的重点将是第一类：**i.i.d. 模型**。

===== Page 23 =====

i.i.d. 是什么意思？

i.i.d. 代表独立同分布。

一个基本假设

它是统计学和机器学习中关于随机变量集合的一个常见且关键的假设。

让我们分解一个随机变量序列 \( X_1, X_2, X_3, \ldots, X_n \)。

===== Page 24 =====

第 1 部分：同分布 (i.d.)

所有变量服从相同的概率分布。

- 它们有相同的均值：
  \[    E[X_1] = E[X_2] = \ldots = E[X_n] = \mu\]

- 它们有相同的方差：
  \[    \text{Var}(X_1) = \text{Var}(X_2) = \ldots = \text{Var}(X_n) = \sigma^2\]

- 它们有相同的基本概率法则（PDF/PMF）。

例子：

- \( X_1, X_2, \ldots, X_{10} \) 表示一个公平骰子的 10 次投掷。
- 每个 \( X_i \) 的 PMF 为：
  \[    P(X_i = k) = \frac{1}{6} \quad \text{对于} \quad k = 1, 2, \ldots, 6\]

- 它们是同分布的。

===== Page 25 =====

第 2 部分：独立 (i.)

一个变量的结果不影响其他变量。

► 知道 \( X_j \) 的值不会告诉你关于 \( X_i \) 的任何信息（对于 \( i \neq j \)）。

► 联合概率是各个概率的乘积。

对于任意两个变量 \( X_i \) 和 \( X_j \) 以及值 \( a, b \)：

\[P(X_i \leq a, \, X_j \leq b) = P(X_i \leq a) \cdot P(X_j \leq b)\]

例子（续）：

► 第 1 次骰子投掷的结果不影响第 5 次投掷。

► \( P(X_1 = 1, \, X_5 = 6) = P(X_1 = 1) \cdot P(X_5 = 6) = \frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36} \)。

► 它们是独立的。

===== Page 26 =====

全部结合起来：i.i.d.

如果我们的骰子投掷既是独立的又是同分布的，它们就构成一个 **i.i.d. 序列**。

正式定义
序列 \( X_1, X_2, \ldots, X_n \) 是 i.i.d. 的，如果：

1. \((X_1, X_2, \ldots, X_n)\) 是相互**独立的**。
2. 所有 \( X_i \) 都从同一分布 \( F \) 中抽取（它们是**同分布的**）。

===== Page 27 =====

为什么 i.i.d. 假设很重要？

它简化了数学，并且是许多关键定理的基础。

大数定律
对于一个均值为 \(\mu\) 的 i.i.d. 序列：

\[\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{P} \mu\]

样本平均值收敛于真实均值。

中心极限定理
对于一个均值为 \(\mu\)、方差为 \(\sigma^2\) 的 i.i.d. 序列：

\[\sqrt{n}(\bar{X}_n - \mu) \xrightarrow{d} \mathcal{N}(0, \sigma^2)\]

样本均值近似服从正态分布。

这个假设对于许多统计推断和机器学习算法至关重要。

===== Page 28 =====

# 贝叶斯视角 I

机器学习模型通常基于参数化的概率模型。核心目标是从观测数据中估计该模型的参数。

一种系统的方法是贝叶斯估计，它将参数 \(\mathbf{w}\) 本身视为随机变量。这引出了贝叶斯定理：

用于参数估计的贝叶斯定理
\[p(\mathbf{w} \mid \mathbf{x}) = \frac{p(\mathbf{x} \mid \mathbf{w}) \, p(\mathbf{w})}{p(\mathbf{x})}\]

- \(p(\mathbf{w})\): 先验概率 —— 我们在看到数据之前对 \(\mathbf{w}\) 的信念。
- \(p(\mathbf{x} \mid \mathbf{w})\): 似然 —— 给定参数时数据的概率。

===== Page 29 =====

# 贝叶斯视角 II

- \( p(w \mid x) \): **后验**概率 —— 我们在看到数据 *之后* 对 w 更新后的信念。

- \( p(x) \): **证据** 或边缘似然。

===== Page 30 =====

难处理的后验问题
在贝叶斯估计中，我们希望得到给定数据 \(D\) 后参数 \(\mathbf{w}\) 的完整后验分布：

\[p(\mathbf{w} \mid D) = \frac{p(D \mid \mathbf{w}) \, p(\mathbf{w})}{p(D)}\]

挑战
边缘似然 \(p(D) = \int p(D \mid \mathbf{w}) p(\mathbf{w}) \, d\mathbf{w}\) 对于复杂模型通常难以处理。我们无法以闭式形式计算后验。

常见解决方案

- MCMC 采样（准确，但慢），将在后面讨论
- 变分推断（快，但有偏），将在后面讨论
- MAP 和拉普拉斯近似（基于优化的快速方法）

===== Page 31 =====

最大后验概率 (MAP) 估计：

\[ w_{MAP}^* = \arg \max_w p(w | x) = \arg \max_w p(x | w) \, p(w) \]

最大似然估计 (MLE) 是均匀先验下的特例：

\[ w_{MLE}^* = \arg \max_w p(x | w) = \arg \max_w \prod_{i=1}^{N} p(x_i | w) \]

拉普拉斯近似

===== Page 32 =====

# 拉普拉斯近似：核心思想

用高斯分布 \( q(w) \) 近似真实后验 \( p(w \mid D) \)，通过：

1. 找到其众数（**MAP 估计**）。
2. 在该众数处匹配其曲率。

\[p(w \mid D)\]

真实后验
拉普拉斯近似 \( N(\text{w}_{MAP}, \mathbf{H}^{-1}) \)

不确定性 \(\propto \mathbf{H}^{-1}\)

===== Page 33 =====

# 数学推导

## 步骤 1：找到众数
找到最大后验概率 (MAP) 估计：

\[w_{MAP} = \arg\max_{w} p(w | D) = \arg\min_{w} \left[ -\log p(D | w) - \log p(w) \right]\]

---

## 步骤 2：在众数处进行泰勒展开

展开负对数后验 \( E(w) = -\log p(w | D) \)：

\[E(w) \approx E(w_{MAP}) + \underbrace{(w - w_{MAP})^T \nabla E(w_{MAP})}_{=0} + \frac{1}{2}(w - w_{MAP})^T \underbrace{\nabla \nabla E(w_{MAP})}_{H} (w - w_{MAP})\]

\[= const + \frac{1}{2}(w - w_{MAP})^T H(w - w_{MAP})\]

---

## 步骤 3：取指数得到近似的高斯后验

\[p(w | D) \propto \exp(-E(w)) \approx \exp\left( -\frac{1}{2}(w - w_{MAP})^T H(w - w_{MAP}) \right]\]

\[\Rightarrow q(w) = \mathcal{N}(w | w_{MAP}, H^{-1})\]

===== Page 34 =====

# 总结、优点和局限性

## 拉普拉斯近似

\[p(\mathbf{w} | \mathbf{D}) \approx \mathcal{N}(\mathbf{w} | \mathbf{w}_{\text{MAP}}, \mathbf{H}^{-1})\]

其中 \(\mathbf{H} = \nabla \nabla [-\log p(\mathbf{D} | \mathbf{w}) - \log p(\mathbf{w})]\) 是 Hessian 矩阵。

---

### 优点
- 简单直观。
- 将积分转化为优化。
- 提供完整的分布估计，而不仅仅是一个众数。

---

### 局限性
- 局部近似。对于多峰、偏斜或重尾的后验效果差。
- 需要计算并求逆 Hessian 矩阵，对于 \(D\) 个参数复杂度为 \(O(D^3)\)。
- 是高斯近似，可能不适用。

===== Page 35 =====

最大似然中的数值考虑 I
在实践中，直接处理概率的乘积会带来数值挑战：

- 将许多概率（都 \( < 1 \)）相乘会导致极小的数字。
- 这可能导致算术下溢（数字太小，超出有限精度）。

一个标准的解决方案是使用负对数似然：

\[w_{MLE}^* = \arg \max_{w} \prod_{i=1}^{N} p(x_i | w)\]
\[= \arg \min_{w} \left( -\sum_{i=1}^{N} \log p(x_i | w) \right)\]

为什么这样更好？

===== Page 36 =====

最大似然中的数值考虑 II

乘积变成了求和，数值上更稳定。

对数函数压缩了值的动态范围。

在优化框架中，最小化通常更标准。

因此，最大似然估计变成了寻找负对数似然函数的最小值。

===== Page 37 =====

第二章：线性模型

===== Page 38 =====

线性回归：一种监督学习方法 I

一项基本的监督学习任务：给定一个包含 \( N \) 个输入-输出对的数据集。

\[D = \{(x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N)\}\]

► \( x_n \in \mathbb{R}^D \): 自变量（\( D \) 维特征向量）

► \( y_n \in \mathbb{R} \): 因变量（一维实值目标）

===== Page 39 =====

线性回归：一种监督学习方法 II

概率模型
我们假设目标 \( y \) 是输入 \( x \) 的______，受到高斯噪声的破坏：

\[P(y | x, w, \sigma^2) = N(y | w^T x, \sigma^2)\]

均值是特征的线性组合：

\[\mu = w^T x = w_0 + w_1 x_1 + \ldots + w_D x_D\]

\( w_0 \) 称为偏置。\( w \) 是一个 \( D + 1 \) 维行向量，而 \( x = [1, x_1, \ldots, x_D]^T \) 是 \( D + 1 \) 维列向量。

从似然到损失函数

===== Page 40 =====

线性回归：一种监督学习方法 III

最大化似然（对 \( w \) 使用均匀先验）等价于最小化负对数似然：

\[E(w) = -\sum_{n=1}^{N} \log N(y_n | w^T x_n, \sigma^2) \propto \sum_{n=1}^{N} (y_n - w^T x_n)^2\]

\[E(w; D) = \frac{1}{2} \sum_{n=1}^{N} (y_n - w^T x_n)^2\]

最大似然解由正规方程给出：

\[w_{ML} = (X^T X)^{-1} X^T y\]

===== Page 41 =====

# 防止过拟合：正则化 I

## 正则化损失函数
为了防止过拟合并提高泛化能力（模型对数据拟合太好，但泛化能力差），我们在损失函数中引入一个惩罚项：

\[E(w; D, \lambda) = \sum_{n=1}^{N} (y_n - w^T x_n)^2 + \lambda \|w\|_2^2\]

这种特定形式被称为 \( L_2 \) 正则化或岭回归。

- \(\lambda \geq 0\): **超参数**，控制正则化强度。
- \(\|w\|_2^2 = \sum_j w_j^2\): 权重向量的平方 \( L_2 \) 范数。

## 贝叶斯解释

===== Page 42 =====

# 防止过拟合：正则化 II

这个公式在贝叶斯框架中有自然的解释。正则化项等价于对参数放置一个高斯（正态）先验：

\[p(w) = \mathcal{N}(w \mid 0, \lambda^{-1}I)\]

最大化后验分布 \( p(w \mid \mathbb{X}, y) \)（MAP 估计）直接导致最小化 \( E(w) \)。

## 解
与原文注释不同，这个正则化问题**确实有闭式解**：

\[w^* = (\mathbf{X}^T \mathbf{X} + \lambda\mathbf{I})^{-1} \mathbf{X}^T y\]

矩阵 \((\mathbf{X}^T \mathbf{X} + \lambda\mathbf{I})\) 总是可逆的，这是 \( L_2 \) 正则化的一个关键优势。

===== Page 43 =====

逻辑回归（分类）

现在数据点是 \((t_1, x_1), \ldots, (t_N, x_N)\)，其中因变量 \(t_i\) 取两个值 \((0, 1)\)。\(x_i\) 也是一个 \(D\) 维向量。

二分类模型

\[P(t|x, w) = \sigma(w^T x)^t(1 - \sigma(w^T x))^{1-t}\]

其中 \(\sigma(x) = \frac{1}{1 + \exp(-x)}\) 是 sigmoid 函数

===== Page 44 =====

联合概率为

\[p(D|w) = \prod_{n=1}^{N} \sigma(\mathbf{w}^T \mathbf{x}_n)^{t_n} (1 - \sigma(\mathbf{w}^T \mathbf{x}_n))^{1-t_n}\]

损失函数
负对数似然：

\[E(\mathbf{w}; D) = -\sum_{n=1}^{N} \left[ t_n \log \sigma(\mathbf{w}^T \mathbf{x}_n) + (1 - t_n) \log(1 - \sigma(\mathbf{w}^T \mathbf{x}_n)) \right]\]

===== Page 45 =====

# 多类分类

数据是 \((t_1, x_1), \ldots, (t_N, x_N)\)，且 \(t_i\) 取 \(K\) 个离散值。
Softmax 回归
类别 \(i\) 的概率：

\[p_i(w; x) = \frac{\exp(\mathbf{w}_i^T\mathbf{x})}{\sum_{j=1}^K \exp(\mathbf{w}_j^T\mathbf{x})}\]

概率分布为

\[p(t|w) = \prod_{i=1}^K p_i(w; x)^{t_i}, \quad p(D|w) = \prod_{n=1}^N \prod_{i=1}^K p_i(w; x_n)^{t_{ni}}\]

由负对数似然得到的损失函数为

\[E(D; w) = -\log p(D|w) = - \sum_{n=1}^N \sum_{i=1}^K t_{ni} \log p_i(w; x_n)\]

这个损失函数称为交叉熵。

===== Page 46 =====

# 总结

给定概率假设并使用贝叶斯方法的 MAP 估计，我们得到参数的损失函数
\[E(D; w)\]

其中 \( D \) 由已知数据组成，下一个目标是找到函数 \( E(D; w) \) 的最小值 \( w^* \)。通常无法找到精确解。

===== Page 47 =====

# 优化问题

大多数机器学习都涉及关于模型参数 \( w \) 最小化损失函数 \( J(w) \)。

\[w^* = \arg\min_{w} J(w)\]

## 挑战
对于复杂模型（例如神经网络），找到解析解是不可能的。我们需要一个迭代算法。

**梯度下降** 是完成此任务的基本算法。

===== Page 48 =====

# 直觉：走下山

- \( \eta \nabla J(w) \) 指向山上（最陡上升方向）。
- 为了最小化，我们向相反方向移动：