## Hierarchical Clustering : 层次聚类
### 核心概念

**层次聚类** 是一类构建聚类层次结构的无监督机器学习算法。与K-Means等需要预先指定聚类数量的算法不同，层次聚类的最终结果是一颗树状结构（称为**树状图**），它展示了数据点是如何从底部（每个点是一个单独的簇）逐步合并（或分裂）到顶部（所有点归于一个簇）的全过程。

简单来说，它回答的不仅是“数据可以分成几类”，更是“这些类别之间有什么样的亲疏关系”。

---

### 主要类型

层次聚类主要有两种策略：

#### 1. 凝聚层次聚类 - **自底向上**

这是最常用、最直观的方法。

*   **核心思想**：开始时将每个数据点视为一个独立的簇，然后迭代地将**最相似**的两个簇合并，直到所有数据点都合并成一个簇。
*   **过程**：
    1.  **开始**：将每个数据点看作一个簇。
    2.  **寻找与合并**：计算所有簇之间的距离（相似度），找到距离最近的两个簇，将它们合并为一个新的簇。
    3.  **更新**：重新计算新簇与其他所有簇之间的距离。
    4.  **重复**：重复步骤2和3，直到所有数据点都合并成一个簇。
*   **比喻**：就像是在社交网络中，一开始每个人都是独立的，然后最要好的两个人成为朋友（形成一个小组），这个小组再去找最亲近的其他个人或小组合并，最终形成一个大社区。

#### 2. 分裂层次聚类 - **自顶向下**

这种方法与凝聚法相反，较少使用，因为计算上更复杂。

*   **核心思想**：开始时将所有数据点视为一个簇，然后迭代地将一个簇**分裂**成更小的簇，直到每个数据点都成为一个独立的簇。
*   **过程**：与凝聚法正好相反。

---

### 关键组成部分

要理解层次聚类，必须掌握以下两个概念：

#### 1. 簇间距离度量

在合并簇时，如何衡量两个“簇”之间的距离？这里有几种常见的方法：

*   **单连接**：两个簇中**最近**的两个数据点之间的距离。
    *   优点：能发现非椭圆形的簇。
    *   缺点：对噪声敏感，容易形成“链条状”的簇。
*   **全连接**：两个簇中**最远**的两个数据点之间的距离。
    *   优点：对噪声相对不敏感，倾向于形成紧凑的、大小相近的簇。
*   **平均连接**：两个簇中所有数据点对之间的**平均**距离。
    *   平衡了单连接和全连接的优缺点，是常用的方法。
*   **沃德法**：专注于簇内的方差。它合并两个簇后，使得新形成的簇的**内部方差增量最小**。
    *   倾向于形成大小相似、形状规则的簇，非常常用。

#### 2. 树状图

这是层次聚类的**可视化输出**和**最终结果**。

*   **X轴**：表示原始的数据点。
*   **Y轴**：表示簇之间的距离（或不相似度）。
*   **如何阅读**：
    *   树的底部叶子代表单个数据点。
    *   从下往上，两条线（分支）连接起来，代表两个簇被合并。
    *   连接点的**Y轴高度**代表了这两个簇合并时的距离。**高度越高，说明被合并的两个簇差异越大**。



---

### 工作流程（以凝聚法为例）

1.  **准备数据**：给定一个包含N个数据点的数据集。
2.  **计算距离矩阵**：计算所有数据点两两之间的距离（如欧氏距离），形成一个N×N的矩阵。
3.  **开始循环**：将每个点视为一个簇。
4.  **合并簇**：
    *   根据选定的连接准则（如平均连接），在距离矩阵中找到距离最近的两个簇。
    *   将这两个簇合并成一个新簇。
5.  **更新距离矩阵**：删除已合并的两个簇的行和列，并加入新簇，重新计算新簇与其他所有簇之间的距离。
6.  **检查终止**：如果只剩下一个簇，则停止。否则，回到步骤4。
7.  **绘制树状图**：根据合并过程绘制树状图。
8.  **决定聚类数量**：分析树状图，选择一个“切割高度”，从而确定最终的聚类数量。

---

### 如何确定最终的聚类数量？

树状图本身并没有告诉你应该分成几类，这需要人工判断。常用的方法是：

*   **观察树状图的“长杆”**：在树状图中寻找**垂直方向跨度最长的线段**。然后，用一条水平线穿过这个长杆，这条水平线与树状图相交的点的数量就是建议的聚类数量。如上图所示，虚线穿过了最长的垂直线段，与树状图有**两个**交点，因此建议将数据分为**2类**。

---

### 优缺点

#### 优点：
*   **无需预先指定K值**：这是相对于K-Means的最大优势。
*   **结果直观**：树状图提供了丰富的可视化信息，展示了数据的层次结构。
*   **易于理解**：聚类过程易于解释和传达。

#### 缺点：
*   **计算复杂度高**：通常为O(n³) 或 O(n²)，不适合非常大的数据集（通常n>1000就比较慢了）。
*   **对噪声和异常值敏感**。
*   **一旦做出合并决策，就无法撤销**，可能导致局部最优。
*   **确定聚类数量存在主观性**。

---

### 应用场景

层次聚类在需要理解数据内部层次结构时非常有用，例如：

*   **生物信息学**：构建基因或物种的系统发育树（进化树）。
*   **社会网络分析**：发现社区结构。
*   **文档分类**：对文本文档进行层次化主题归类。
*   **图像分割**：在图像处理中，将像素分组为区域。

### 总结

**层次聚类** 是一种通过构建树状图来揭示数据多层次分组结构的强大聚类方法。它核心的**凝聚法**从单个点开始，通过不断合并最相似的簇来构建层次，其结果**树状图**不仅给出了聚类结果，还清晰地展示了数据之间的亲疏关系，帮助我们做出更合理的聚类数量决策。